{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60db7fae-a026-4728-975e-46727eabaf8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Handling UPSERTS uisng PySpark\n",
    "\n",
    "### Upsert\n",
    "\n",
    "**Upsert = Update + Insert**\n",
    "\n",
    "An **upsert** is a data operation where:\n",
    "- If a record **already exists**, it is **updated**\n",
    "- If a record **does not exist**, it is **inserted**\n",
    "\n",
    "**Upserts are operations that let you maintain accurate, de-duplicated, and current tables by inserting new records and updating existing ones in a single atomic process**\n",
    "\n",
    "This ensures that the **data is not duplicated** while keeping it **current**, making it essential in analytics, pipelines, CDC (Change Data Capture), and real-time systems\n",
    "\n",
    "### Use Cases\n",
    "- **Incremental ETL/ELT**: Only changed rows are updated, new rows are inserted\n",
    "- **Change Data Capture (CDC)**: Apply inserts and updates from source systems\n",
    "- **Slowly Changing Dimensions (SCD Type 1)**: Overwrite old dimension values with new ones\n",
    "- **Kafka Pipelines**: Keep sync table in sync with event streams\n",
    "- **API Data Ingestion**: External APIs often return both new + updated data\n",
    "\n",
    "### MySQL Syntax\n",
    "\n",
    "```sql\n",
    "INSERT INTO customers (customer_id, email, last_login)\n",
    "VALUES (101, 'plaidt@gmail.com', '2025-12-11')\n",
    "ON DUPLICATE KEY UPDATE\n",
    "    email = VALUES(email),\n",
    "    last_login = VALUES(last_login);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52879610-c7ee-48f6-b45f-a7beefe1f5d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Scenario\n",
    "\n",
    "A retail company recives daily updates for its product catalog, including new products, price changes, and discounted items. Instead of overwriting the entire catalog or simply appending new records, they need to upsert the incoming data, updating existing products with the latest information and inserting new products. This ensures that the catalog remains accurate and up-to-date in real-time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46f49a0a-3530-49bd-a334-f092e734acfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Firstly, we need to create a source table which has the products on which we need to perform upserting. To do that,\n",
    "- Go to `Catalog` and create a catalog named `pyspark_cata`\n",
    "- Configure the catalog as prompted, click `next` and `save`\n",
    "- Create a new schema `source`\n",
    "- Go to `SQL Editor` and select workspace as `pyspark_cata` and schema as `source`\n",
    "- Turn on the Serverless Starter Warehouse compute to run SQL Query\n",
    "- Run the following query before returning to the notebook\n",
    "\n",
    "```sql\n",
    "CREATE TABLE products\n",
    "(\n",
    "  id INT,\n",
    "  name STRING,\n",
    "  price INT,\n",
    "  category STRING,\n",
    "  updated_date TIMESTAMP\n",
    ");\n",
    "\n",
    "INSERT INTO products VALUES\n",
    "(1, 'iPhone', 1000, 'electronics', current_timestamp()),\n",
    "(2, 'Macbook', 2000, 'electronics', current_timestamp()),\n",
    "(3, 'T-Shirt', 50, 'clothing', current_timestamp()),\n",
    "(4, 'Shirt', 100, 'clothing', current_timestamp()),\n",
    "(5, 'Pants', 200, 'clothing', current_timestamp()),\n",
    "(6, 'Shoes', 300, 'shoes', current_timestamp()),\n",
    "(7, 'Sneakers', 50, 'shoes', current_timestamp());\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b153d4c8-722b-46f8-bed2-3f287d71f938",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Querying Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e49dcda-3f23-47c3-8a04-d9ec5fcb09b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>price</th><th>category</th><th>updated_date</th></tr></thead><tbody><tr><td>1</td><td>iPhone</td><td>1000</td><td>electronics</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>2</td><td>Macbook</td><td>2000</td><td>electronics</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>3</td><td>T-Shirt</td><td>50</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>4</td><td>Shirt</td><td>100</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>5</td><td>Pants</td><td>200</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>6</td><td>Shoes</td><td>300</td><td>shoes</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>7</td><td>Sneakers</td><td>50</td><td>shoes</td><td>2025-12-11T14:17:04.127Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "iPhone",
         1000,
         "electronics",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         2,
         "Macbook",
         2000,
         "electronics",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         3,
         "T-Shirt",
         50,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         4,
         "Shirt",
         100,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         5,
         "Pants",
         200,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         6,
         "Shoes",
         300,
         "shoes",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         7,
         "Sneakers",
         50,
         "shoes",
         "2025-12-11T14:17:04.127Z"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "price",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "updated_date",
            "nullable": true,
            "type": "timestamp"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 2
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "price",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "updated_date",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM pyspark_cata.source.products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "471ceef2-0520-40d5-b4f9-38567b7ebf78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>price</th><th>category</th><th>updated_date</th></tr></thead><tbody><tr><td>1</td><td>iPhone</td><td>1000</td><td>electronics</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>2</td><td>Macbook</td><td>2000</td><td>electronics</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>3</td><td>T-Shirt</td><td>50</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>4</td><td>Shirt</td><td>100</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>5</td><td>Pants</td><td>200</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>6</td><td>Shoes</td><td>300</td><td>shoes</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>7</td><td>Sneakers</td><td>50</td><td>shoes</td><td>2025-12-11T14:17:04.127Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "iPhone",
         1000,
         "electronics",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         2,
         "Macbook",
         2000,
         "electronics",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         3,
         "T-Shirt",
         50,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         4,
         "Shirt",
         100,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         5,
         "Pants",
         200,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         6,
         "Shoes",
         300,
         "shoes",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         7,
         "Sneakers",
         50,
         "shoes",
         "2025-12-11T14:17:04.127Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "price",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "updated_date",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.sql(\"select * from pyspark_cata.source.products\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58cb9f95-cff3-449a-8b22-e4c643b8a752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we can see the data through the table we created. The next part is performing the upserts operation but for that, we require a **destination** where the upserted data will be stored. If you are not provided with destination in interviews, make sure to ask where is the destination or where do we sink the data.\n",
    "\n",
    "So we create the destination in Databricks\n",
    "- Goto our `source` and create volume `db_volume`\n",
    "- Create a directory `products_sink` in `db_volume`\n",
    "\n",
    "PS: Volumes are a managed storage location iside Unity Catalog used for storing files instead of tables. Think of it as a file sytem directory inside a Catalog and Schema, governed by Unity Catalog "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f50fc33d-f492-44a5-9382-007597a749e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Upserting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0a56fc3-8de5-45f6-86c3-cea0307e3370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is being Upserted\n"
     ]
    }
   ],
   "source": [
    "# Creating Delta Object\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Setting guard-rails by using try-except so that Upsert doesn't fail if the table doesn't \n",
    "# We can also use 'if spark.catalog.tableExists():'\n",
    "# or\n",
    "# 'if dbutils.fs.ls(\"/Volumes/pyspark_cata/source/db_volume/products_sink/\"):'\n",
    "\n",
    "try:\n",
    "    dlt_obj = DeltaTable.forPath(spark, \"/Volumes/pyspark_cata/source/db_volume/products_sink/\")\n",
    "\n",
    "    # The condition in whenMatchedUpdateAll() is optional.\n",
    "    # It is used to prevent updating the data if the source data is older than the target data.\n",
    "    # However, in real-world, if we need to backfill the data, this condition can be useful to not lose latest\n",
    "    # data\n",
    "\n",
    "    dlt_obj.alias(\"tgt\").merge(\n",
    "        df.alias(\"src\"), \"src.id = tgt.id\"\n",
    "    ).whenMatchedUpdateAll(condition=\"src.updated_date >= tgt.updated_date\")\\\n",
    "        .whenNotMatchedInsertAll().execute()\n",
    "    print(\"The data is being Upserted\")\n",
    "\n",
    "except:\n",
    "    df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .save(\"/Volumes/pyspark_cata/source/db_volume/products_sink/\")\n",
    "    print(\"The data is being Written\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a12fdf2-60c9-4624-98dc-49c55bf4fd57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>price</th><th>category</th><th>updated_date</th></tr></thead><tbody><tr><td>1</td><td>iPhone</td><td>1000</td><td>electronics</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>2</td><td>Macbook</td><td>2000</td><td>electronics</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>3</td><td>T-Shirt</td><td>50</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>4</td><td>Shirt</td><td>100</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>5</td><td>Pants</td><td>200</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>6</td><td>Shoes</td><td>300</td><td>shoes</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>7</td><td>Sneakers</td><td>50</td><td>shoes</td><td>2025-12-11T14:17:04.127Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "iPhone",
         1000,
         "electronics",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         2,
         "Macbook",
         2000,
         "electronics",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         3,
         "T-Shirt",
         50,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         4,
         "Shirt",
         100,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         5,
         "Pants",
         200,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         6,
         "Shoes",
         300,
         "shoes",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         7,
         "Sneakers",
         50,
         "shoes",
         "2025-12-11T14:17:04.127Z"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "price",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "updated_date",
            "nullable": true,
            "type": "timestamp"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 38
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "price",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "updated_date",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM delta.`/Volumes/pyspark_cata/source/db_volume/products_sink/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35b0a239-55ac-4ec0-bce7-c975e9da85b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Now this should perform Upsert efficiently. But there is a catch! Let's say we go back to our SQL Editor and insert value where for id 5, instead of pants, it now has trousers. The pipeline would fail. Let's see how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f2a2eb5-f722-4319-90e7-4263cf838c8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>price</th><th>category</th><th>updated_date</th></tr></thead><tbody><tr><td>1</td><td>iPhone</td><td>1000</td><td>electronics</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>2</td><td>Macbook</td><td>2000</td><td>electronics</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>3</td><td>T-Shirt</td><td>50</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>4</td><td>Shirt</td><td>100</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>5</td><td>Pants</td><td>200</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>6</td><td>Shoes</td><td>300</td><td>shoes</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>7</td><td>Sneakers</td><td>50</td><td>shoes</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>5</td><td>Trouser</td><td>150</td><td>clothing</td><td>2025-12-11T15:07:35.984Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "iPhone",
         1000,
         "electronics",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         2,
         "Macbook",
         2000,
         "electronics",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         3,
         "T-Shirt",
         50,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         4,
         "Shirt",
         100,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         5,
         "Pants",
         200,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         6,
         "Shoes",
         300,
         "shoes",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         7,
         "Sneakers",
         50,
         "shoes",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         5,
         "Trouser",
         150,
         "clothing",
         "2025-12-11T15:07:35.984Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "price",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "updated_date",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.sql(\"select * from pyspark_cata.source.products\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17bf786f-bb21-4fab-acc6-5be091e24901",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dlt_obj = DeltaTable.forPath(spark, \"/Volumes/pyspark_cata/source/db_volume/products_sink/\")\n",
    "dlt_obj.alias(\"tgt\").merge(\n",
    "    df.alias(\"src\"), \"src.id = tgt.id\"\n",
    ").whenMatchedUpdateAll(condition=\"src.updated_date >= tgt.updated_date\")\\\n",
    "    .whenNotMatchedInsertAll().execute()\n",
    "print(\"The data is being Upserted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb48ad02-7b31-4b61-b265-390c7703ec8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Error\n",
    "```\n",
    "[DELTA_MULTIPLE_SOURCE_ROW_MATCHING_TARGET_ROW_IN_MERGE] Cannot perform Merge as multiple source rows matched and attempted to modify the same\n",
    "target row in the Delta table in possibly conflicting ways. By SQL semantics of Merge,\n",
    "when multiple source rows match on the same target row, the result may be ambiguous\n",
    "as it is unclear which source row should be used to update or delete the matching\n",
    "target row. You can preprocess the source table to eliminate the possibility of\n",
    "multiple matches. Please refer to\n",
    "https://docs.databricks.com/delta/merge.html#merge-error\n",
    " SQLSTATE: 21506\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eee2b23d-e6df-402e-9c26-97fc23392edd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To fix this, we need de-duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "878ff9b9-074b-4e29-89d0-1a0899fee255",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "419ec99f-bb69-4c9a-adf2-4f764b1b0d3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>price</th><th>category</th><th>updated_date</th></tr></thead><tbody><tr><td>1</td><td>iPhone</td><td>1000</td><td>electronics</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>2</td><td>Macbook</td><td>2000</td><td>electronics</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>3</td><td>T-Shirt</td><td>50</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>4</td><td>Shirt</td><td>100</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>5</td><td>Trouser</td><td>150</td><td>clothing</td><td>2025-12-11T15:07:35.984Z</td></tr><tr><td>6</td><td>Shoes</td><td>300</td><td>shoes</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>7</td><td>Sneakers</td><td>50</td><td>shoes</td><td>2025-12-11T14:17:04.127Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "iPhone",
         1000,
         "electronics",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         2,
         "Macbook",
         2000,
         "electronics",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         3,
         "T-Shirt",
         50,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         4,
         "Shirt",
         100,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         5,
         "Trouser",
         150,
         "clothing",
         "2025-12-11T15:07:35.984Z"
        ],
        [
         6,
         "Shoes",
         300,
         "shoes",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         7,
         "Sneakers",
         50,
         "shoes",
         "2025-12-11T14:17:04.127Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "price",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "updated_date",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.sql(\"select * from pyspark_cata.source.products\")\n",
    "#Dedup\n",
    "df = df.withColumn('dedup', row_number().over(Window.partitionBy('id').orderBy(desc('updated_date'))))\n",
    "df = df.filter(col('dedup') == 1).drop('dedup')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77545f81-22b2-4f4e-8f8d-4a42f04689f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is being Upserted\n"
     ]
    }
   ],
   "source": [
    "# Creating Delta Object\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Setting guard-rails by using try-except so that Upsert doesn't fail if the table doesn't exist\n",
    "try:\n",
    "    dlt_obj = DeltaTable.forPath(spark, \"/Volumes/pyspark_cata/source/db_volume/products_sink/\")\n",
    "    dlt_obj.alias(\"tgt\").merge(\n",
    "        df.alias(\"src\"), \"src.id = tgt.id\"\n",
    "    ).whenMatchedUpdateAll(condition=\"src.updated_date >= tgt.updated_date\")\\\n",
    "        .whenNotMatchedInsertAll().execute()\n",
    "    print(\"The data is being Upserted\")\n",
    "\n",
    "except:\n",
    "    df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .save(\"/Volumes/pyspark_cata/source/db_volume/products_sink/\")\n",
    "    print(\"The data is being Written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fbc3264-a5d4-49ce-b776-af51be86ce19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>price</th><th>category</th><th>updated_date</th></tr></thead><tbody><tr><td>1</td><td>iPhone</td><td>1000</td><td>electronics</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>2</td><td>Macbook</td><td>2000</td><td>electronics</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>3</td><td>T-Shirt</td><td>50</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>4</td><td>Shirt</td><td>100</td><td>clothing</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>5</td><td>Trouser</td><td>150</td><td>clothing</td><td>2025-12-11T15:07:35.984Z</td></tr><tr><td>6</td><td>Shoes</td><td>300</td><td>shoes</td><td>2025-12-11T14:17:04.127Z</td></tr><tr><td>7</td><td>Sneakers</td><td>50</td><td>shoes</td><td>2025-12-11T14:17:04.127Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "iPhone",
         1000,
         "electronics",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         2,
         "Macbook",
         2000,
         "electronics",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         3,
         "T-Shirt",
         50,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         4,
         "Shirt",
         100,
         "clothing",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         5,
         "Trouser",
         150,
         "clothing",
         "2025-12-11T15:07:35.984Z"
        ],
        [
         6,
         "Shoes",
         300,
         "shoes",
         "2025-12-11T14:17:04.127Z"
        ],
        [
         7,
         "Sneakers",
         50,
         "shoes",
         "2025-12-11T14:17:04.127Z"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "price",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "updated_date",
            "nullable": true,
            "type": "timestamp"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 61
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "price",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "updated_date",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM delta.`/Volumes/pyspark_cata/source/db_volume/products_sink/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9af55939-bae0-4cae-8e68-de92641eafd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we have also solved the problem of duplications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef4337ca-bd72-4c97-a63b-7b4a1b95ff27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "https://docs.delta.io/latest/delta/delta-update.html"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8525702737021080,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Upserts",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
